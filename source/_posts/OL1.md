---
title: Kullback-Leibler Divergence
date: 2026-01-26
tag: [online learning]
category: [Mathematical Foundation]
math: true
---

KL 散度（Kullback-Leibler Divergence）

<!--more-->

# Kullback-Leibler (KL) Divergence

对有限动作集 $\mathcal A$ 上的两个分布 $p,q\in\Delta(\mathcal A)$，KL 散度定义为

$$
\mathrm{KL}(p\|q)=\sum_{a\in\mathcal A} p(a)\log\frac{p(a)}{q(a)}.
$$
这其实是

$$
\mathrm{KL}(p\|q)=\mathbb E_{a\sim p}\Big[\log p(a)-\log q(a)\Big]
$$
即，当真实分布是 $p$ 时，你用 $q$ 来“解释/编码”样本，会额外付出的平均对数代价。

>  如果你做统计/ML：这就是“用模型 $q$”相对“真实模型 $p$”的**期望 log-likelihood 损失差**。
> 这就是 KL 的本质：**“错模型的平均代价”**，而不是空间几何意义上的距离。

## 信息论视角

想象你正在设计一套摩尔斯电码（编码方案 $Q$）来传输英文字母（真实分布 $P$）。

- **真实情况（$P$）：** 在英语中，字母 **"e"** 出现得非常频繁（约 12%），而 **"z"** 出现得非常少（约 0.07%）。
- **理想策略：** 为了让总的电报长度最短，你应该给高频词 **"e"** 分配最短的编码（比如 `.`），给低频词 **"z"** 分配最长的编码（比如 `--..`）。

**现在，如果你搞错了（即 $Q$ 不等于 $P$）：**

如果你误以为 **"z"** 很常用，而 **"e"** 很罕见（这是你的错误分布 $Q$），你会给 **"z"** 分配短码，给 **"e"** 分配很长的码。

**结果（额外代价）：**

当真实的英语文章（$P$）传过来时，你会发现你不得不一遍又一遍地为那个频繁出现的 **"e"** 发送那个超长的编码。你的电报总长度会比“最佳方案”长出很多。

**KL 散度就是这一段“额外多出来的长度”。**

### 拆解 KL 散度公式

让我们把这个直觉映射到公式上。KL 散度的公式通常写为：

$$
D_{KL}(P || Q) = \sum_{x} P(x) \log \frac{P(x)}{Q(x)}
$$

为了看清“代价”，我们利用对数性质 $\log(a/b) = \log a - \log b$，把它拆成两部分：

$$
D_{KL}(P || Q) = \underbrace{\sum P(x) \log P(x)}_{\text{- 熵 (Entropy)}} - \underbrace{\sum P(x) \log Q(x)}_{\text{- 交叉熵 (Cross Entropy)}}
$$

也就是：

$$
D_{KL}(P || Q) = \underbrace{-\sum P(x) \log Q(x)}_{\text{实际付出的总代价}} - \underbrace{(-\sum P(x) \log P(x))}_{\text{理论最低代价}}
$$

让我们逐个拆解这里面的每一个零件：

#### A. $\log \frac{1}{Q(x)}$ （或者 $-\log Q(x)$）：你设计的编码长度

在信息论中，香农告诉我们要为一个发生概率为 $q$ 的事件编码，最佳长度是 $-\log q$。

- 如果 $Q(x)$ 很大（你认为 $x$ 经常发生），$\log \frac{1}{Q(x)}$ 就很小（你给它设计了短码）。
- 如果 $Q(x)$ 很小（你认为 $x$ 很少发生），$\log \frac{1}{Q(x)}$ 就很大（你给它设计了长码）。

**这是你基于你的猜测 $Q$ 准备付出的“单次代价”。**

> 要理解为什么是 $-\log q$，我们需要把“信息”看作是为了消除**不确定性**所需要做出的**决策次数**。
>
> 假设我在心里想了一个东西，你需要通过问“是/否”的问题来猜出它是谁。每一个“是/否”就是一个比特（Bit）。**“最佳编码长度”就是让你猜中这个东西所需的最小提问次数。**
>
> 假设我有 8 个球，其中只有 1 个是红球，其他是白球。
>
> - 红球在任何位置的概率都是均等的，即 $q = 1/8$。
> - 你需要问几次才能保证找出红球？
>
> 最聪明的方法是**二分法**：
>
> 1. “红球在前 4 个里吗？” -> 排除一半。
> 2. “红球在前 2 个里吗？” -> 再排除一半。
> 3. “是这 1 个吗？” -> 锁定目标。
>
> 你刚好需要 **3 次**提问。
>
> 我们来看数学关系：$2^3 = 8$，或者倒过来 $\log_2(8) = 3$。
>
> 因为概率 $q = 1/8$，所以：
>
> $$
> -\log_2(1/8) = \log_2(8) = 3
> $$
>
> **结论：** 如果一个事件发生的概率是 $1/2^k$，你恰好需要 $k$ 个比特（问题）来锁定它。所以最佳长度就是 $-\log_2 q$。
>
> **为什么要用对数 (Log)？**
>
> 这是更深层的数学原因：**信息必须是可叠加的。**
>
> 想象我们要传输两个**独立**的事件：
>
> - 事件 A：明天下雨（需要 1 个比特来记录）。
> - 事件 B：股市上涨（需要 1 个比特来记录）。
>
> 如果你要同时记录这两个事件，你显然需要 $1 + 1 = 2$ 个比特。
>
> 但是，从概率角度看，两个独立事件同时发生的概率是**相乘**的：
>
> $$
> P(A \text{ and } B) = P(A) \times P(B)
> $$
>
> 我们需要一个函数 $f$，能够把“概率的乘法”转换成“比特数的加法”：
>
> $$
> f(x \cdot y) = f(x) + f(y)
> $$
>
> 在数学世界里，**唯一**能把乘法变成加法的连续函数，就是**对数函数 ($\log$)**。
>
> 由于概率 $q$ 是 $0$ 到 $1$ 之间的小数，$\log q$ 是负数，而长度不能是负的，所以我们加个负号：
>
> $$
> \text{Length} = -\log q
> $$
>
> **熵（Entropy）的意义是什么？**
>
> 既然 $-\log P(x)$ 是**某一个**特定事件的信息量（惊奇程度），那么**熵**就是**整个系统**的**平均**信息量（平均惊奇程度）。
>
> 公式：
>
> $$
> H(P) = \sum_{x} P(x) \cdot \underbrace{(-\log P(x))}_{\text{每个事件的信息量}}
> $$
>
> 也就是：**期望值（Weighted Average）**。
>
> **熵的物理意义：混乱度 / 不确定性**
>
> 熵衡量的是**“我想把这件事说清楚，平均需要费多少口舌”。**
>
> 让我们对比两种情况（比如抛硬币）：
>
> - **情况 A：完全确定的世界 (低熵)**
>   - 这枚硬币两面都是人头。
>   - $P(\text{人头}) = 1$, $P(\text{字}) = 0$。
>   - 不管你抛几次，结果都是确定的。你需要发短信告诉我结果吗？不需要。你完全不用发任何比特。
>   - **熵 = 0**。
> - **情况 B：完全混乱的世界 (高熵)**
>   - 这枚硬币是公平的。
>   - $P(\text{人头}) = 0.5$, $P(\text{字}) = 0.5$。
>   - 结果完全无法预测。你想告诉我结果，必须老老实实发 1 个比特（0 或 1）。
>   - **熵 = 1**（这是 2 分类问题的最大熵）。
>
> **熵的信息论意义：数据的“压缩极限”**
>
> 这是香农最伟大的贡献：**熵定义了无损压缩的物理极限。**
>
> 如果一个语言（比如英语）的熵是 1.5 比特/字母。
>
> - 意思是：虽然我们用了 26 个字母（通常需要 $\log_2 26 \approx 4.7$ 比特来存储一个字母），但因为有些词太常用了（比如 "the", "is"），实际上平均每个字母只包含 1.5 比特的信息。
> - 如果你设计的压缩算法，平均下来每个字母用的空间小于 1.5 比特，你就一定会丢失信息（有损压缩）。
> - 如果你用的空间多于 1.5 比特，说明你的算法还有优化空间（这就是 KL 散度里的那个“额外代价”）。
>
> **总结**
>
> 1. **$-\log q$**：因为概率越小（越稀有），这件事发生了就越“惊人”，为了在所有的可能中锁定它，我们需要切分的次数（二分法深度）就越多，也就是编码越长。对数函数是为了让“独立事件的信息量”可以做加法。
> 2. **熵 (Entropy)**：是对整个系统中所有可能发生的事件，根据它们发生的概率，计算出的**平均**不确定性。它是数据压缩不可突破的“理论地板”。
>

#### B. $P(x)$：现实打脸的频率

这是真实世界 $P$ 实际将样本 $x$ 扔到你脸上的频率。

无论你设计了多短或多长的码，你必须按照 $P(x)$ 的频率去使用它。

#### C. 第一项： $-\sum P(x) \log Q(x)$ （交叉熵）

这是**当你手握错误的地图 $Q$，但在走真实的地形 $P$ 时，你平均每一步走的距离。**

你按照 $Q$ 设计了编码长度，但必须按照 $P$ 的频率来累加这些长度。

#### D. 第二项： $-\sum P(x) \log P(x)$ （熵，即 $H(P)$）

这是**上帝视角的最优解**。如果你完全知道了真实分布 $P$，并据此设计了完美的编码方案，你平均每一步需要的最小距离。这被认为是数据的“固有不确定性”或“固有长度”。

### 为什么是“额外”的代价？

现在把上面两部分减一下：

$$\text{KL散度} = (\text{用错误分布 Q 编码的平均长度}) - (\text{用完美分布 P 编码的平均长度})$$

- 如果 $Q$ 和 $P$ 完全一样：你的编码是完美的，实际长度 = 理论最低长度，相减为 0。KL 散度为 0。
- 如果 $Q$ 和 $P$ 差异很大：你在高频事件上用了长码，或者在低频事件上浪费了短码。实际长度 > 理论最低长度，相减 > 0。

所以，KL 散度度量的就是**信息损失**，或者叫**编码效率的降低**。

> **一个具体的数字例子**
>
> 假设只有两个天气：**晴天**和**雨天**。
>
> - **真实分布 $P$ (西雅图):**
>   - 雨天: 90% ($P=0.9$)
>   - 晴天: 10% ($P=0.1$)
> - **你的错误模型 $Q$ (你以为你在撒哈拉):**
>   - 雨天: 10% ($Q=0.1$)
>   - 晴天: 90% ($Q=0.9$)
>
> **根据信息论（使用 $\log_2$ 以比特为单位）：**
>
> 1. **你设计的编码 ($Q$):**
>
>    - 你以为晴天常有，给晴天短码：长度 $\approx \log_2(1/0.9) = 0.15$ bits。
>    - 你以为雨天罕见，给雨天长码（报警信号）：长度 $\approx \log_2(1/0.1) = 3.32$ bits。
>
> 2. **现实的打击 ($P$):**
>
>    - 现实是 90% 的日子都在下雨。
>    - 所以你不得不 90% 的时间都在发送那个超长的“报警信号” (3.32 bits)。
>
> 3. **计算平均代价 (交叉熵):**
>
>    $$0.9 \times 3.32 + 0.1 \times 0.15 = \mathbf{3.00 \text{ bits}}$$
>
>    你平均每天发 3 个比特的数据。
>
> 4. **如果用最佳策略 ($P$) 的代价 (熵):**
>
>    - 如果按照 $P$ 编码，雨天给短码 (0.15)，晴天给长码 (3.32)。
>    - 平均代价：$0.9 \times 0.15 + 0.1 \times 3.32 = \mathbf{0.47 \text{ bits}} $。
>
> 5. **KL 散度 (额外的冤枉路):**
>
>    $$3.00 - 0.47 = \mathbf{2.53 \text{ bits}}$$
>
> **结论：** 因为你错误地用 $Q$ (撒哈拉模型) 来编码 $P$ (西雅图现实)，你平均每天**多浪费了 2.53 个比特**的资源。这就是 KL 散度。

## 基本性质

KL 散度更像是“罚函数/势能”，而不是“几何距离”。它不是距离，KL **不对称**、**不满足三角不等式**：

非负性：Gibbs 不等式（或 Jensen）
$$
\mathrm{KL}(p\|q)\ge 0.
$$
当且仅当 $p=q$ 时等号成立。

$\mathrm{KL}(p\|q)\neq \mathrm{KL}(q\|p)$ 一般成立，如果 $q(a)=0$ 但 $p(a)>0$，则 $\mathrm{KL}(p\|q)=+\infty$。
这在概率建模里很合理：你给了某事件零概率，但它真实会发生，那 log-loss 直接炸掉。

## 前向 KL 散度（Forward KL）

在机器学习中，我们通常假设 $P$ 是**真实分布**（无法改变），而 $Q$ 是我们的**模型分布**（我们在调整它来拟合 $P$）。这两种“拟合方向”具有本质上的区别。

**公式：** 
$$
D_{KL}(P || Q) = \sum P(x) \log \frac{P(x)}{Q(x)}
$$

**别名：** 零回避 (Zero Avoiding)、平均搜索 (Mean Seeking)

**典型应用：** 极大似然估计 (MLE)，即大多数监督学习。

#### 直觉理解：

这里的权重是 $P(x)$。

- **如果不拟合会怎样？**

  如果对于某个样本 $x$，真实分布 $P(x) > 0$（真的发生了），但你的模型认为 $Q(x) \approx 0$（绝不可能发生）。

  那么 $\frac{P(x)}{Q(x)} \to \infty$，导致 $\log$ 爆炸，**代价无穷大**。

#### 行为特征：**“宁滥勿缺” (Inclusive)**

为了避免产生无穷大的惩罚，模型 $Q$ 会强迫自己**覆盖**住 $P$ 有概率的所有区域。

- 哪怕 $Q$ 必须把自己变得很宽、很平，甚至覆盖到一些 $P$ 根本没有概率的区域，它也在所不惜。它必须保证：“只要 $P$ 有，我就得有”。

## 后向 KL 散度 (Reverse KL)

**公式：** 

$$
D_{KL}(Q || P) = \sum Q(x) \log \frac{Q(x)}{P(x)}
$$

**别名：** 零强迫 (Zero Forcing)、众数搜索 (Mode Seeking)

**典型应用：** 变分推断 (Variational Inference, VAE)，强化学习。

#### 直觉理解：

这里的权重是 $Q(x)$。

- **如果不拟合会怎样？**

  注意分母现在变成了 $P(x)$。

  如果你的模型预测 $Q(x) > 0$（你说会发生），但真实分布 $P(x) \approx 0$（实际不可能发生）。

  那么 $\frac{Q(x)}{P(x)} \to \infty$，**代价无穷大**。

#### 行为特征：**“宁缺勿滥” (Exclusive)**

为了安全，模型 $Q$ 会变得非常保守。它只敢在 $P$ 概率很高的地方说“有”。

- 只要 $P$ 是 0 的地方，$Q$ 必须也是 0。
- 如果 $P$ 有两个分开的山峰，$Q$ 无法同时覆盖，它会选择**其中一个最高的山峰**（众数），死死地守在那里，而完全忽略另一个山峰。因为它如果试图跨越两个山峰，中间的低谷区域（$P \approx 0$）会让它付出惨重代价。



>视觉化的经典例子：双峰分布
>
>想象真实分布 $P$ 是**两座山峰**（双峰分布），中间隔着一个深谷。如果你只能用一个**单峰**的高斯分布 $Q$ 去拟合它：
>
>1. **前向 KL (Forward $KL(P||Q)$):**
>  - **策略：** 我都要！
>  - **结果：** $Q$ 会变成一个**非常宽**的大鼓包，笼罩住两座山峰。
>   - **副作用：** 它的中心恰恰是在 $P$ 的深谷（概率最低）的地方。它为了覆盖两边，给中间的“无人区”也分配了很高的概率。
>   - **像什么：** 这种模型生成的图片可能会模糊（因为它试图平均化所有可能性）。
> 2. **后向 KL (Reverse $KL(Q||P)$):**
>   - **策略：** 选一个最安全的！
>  - **结果：** $Q$ 会选两座山峰里较高的那一座，**变得很窄**，紧紧贴合那一座山。它会完全放弃另一座山。
>   - **副作用：** 丢失了多样性（Mode Collapse）。它永远不会生成另一座山的数据。
>   - **像什么：** 这种模型生成的图片通常很清晰（因为它专注于某一种特定的可能性），但种类很少（生成的全是同一种类型的脸）。
> 

