---
title: LLM
date: 2025-11-28
tags: [others]
categories: [misc]
math: true
---


一些 LLM 相关的东西，最后更新于 2026.1


<!--more-->

# prompt

## 思考问题

>我在研究 XXX，目标是从 A 推导到 B
>
>已知条件 XXX，假设 YYY，约束 ZZZ...
>
>在推导前，请先用你自己的话总结问题和假设，确认理解无误
>
>使用 X 方法进行推导，不要跳步
>
>每一步请明确指出使用了哪些假设
>
>若引入新符号，请显式定义；不要复用已有符号
>
>如果使用某定理，请说明适用条件；不确定的地方请标注“需核实”



>给我这个问题的直觉和数学草图，不需要太严谨，但要逻辑正确
>
>请用另一种方法独立推导同一结论，并对比两种方法的关键差异
>
>假设我是熟悉该领域但对这个技巧不熟的人，请解释第 X 步为什么成立

## 搜索文献

>1.确保引用真实文献，作者/标题/期刊/年份等信息须准确。如对某项文献的真实性存疑，应标注“可能存在不确定性”或不予引用。
>2.优先引用近五年文献（2020年及之后）发表于核心数据库的文献。 
>3.参考文献采用结构化的列表呈现，需提供有效DOI链接（若可获取）。

# 常用大模型能力评估

2026.1：测试问题和测试结果均已经过时

## 评分标准

| 得分 | 表现 |
| ------------ | ------------ |
| 10 | 一次对话，过程与答案均正确 |
| 9 | 一次对话，答案正确，过程出现细微问题或不够详细 |
| 8 | 一次对话，答案正确，过程出现错误但思路正确 |
| 7 | 初次回答错误但思路正确，提示后答对 |
| 6 | 初次回答错误但思路部分正确，多次提示后答对 |
| 5 | 思路混乱，多次提示后得到正确思路 |
| 4 | 思路混乱，多次提示后改善并承认无法求解问题 |
| 3 | 反复尝试错误思路，无法通过提示改善 |
| 2 | 逻辑混乱，无法完全理解问题 |
| 1 | 答非所问或严重逻辑性错误 |
| 0 | 模型故障 |

9-10分说明模型的能力高于所测试问题的水准。
7-8分的表现有助于提升工作效率。
5-6分的表现差强人意，难以处理高难度的任务，属于勉强能用。
4分及以下的表现几乎是在浪费用户的时间。

## 测试结果

- ChatGPT 5.1
- Gemini 3.0 pro
- Grok 4 thinking
- Kimi K2 thinking
- Qwen3-Max thinking
- deepseek 671b R1
- doubao-seed-1.6-thinking

|   | ChatGPT | Gemini | Grok  | Kimi| Qwen  |deepseek |豆包 |
| ------------ | ------------ | ------------ | ------------ | ------------ | ------------ | ------------ |------------ |
|  1 | 10  | 10  | 10 | 6 | 3 |8 |9 |
|  2|  10 |  10 | 9 | 9 | 10 | 7|9 |
|  3 |  6 | 7 | 2 | 6 | 2 | 2 |2|
|  4| 10 |  10 | 9/0 | 3 | 7 | 3 |10|
|  5|  6 | 6 | 6 | 6 | 2 | 3 | 3|
|  6| 9 | 10 | 8 | 7 | 6 | 7|7|
|  ~~7~~| - | - | - | - | - |-|-|
|  8| 6 | 9 | 6 | 8 | 3 | 5/3|3|
|  总分 | 57 | 62 | 50/41 | 45 | 33 |35/33 |43|



2026年2月，Gemini 3.1 和 GPT 5.2 在一些较为小众的领域，仍存在严重的幻觉。
